"""
Quick test script for optimized Gemini API timeout handling
"""

import asyncio
import time
from comprehensive_ai_agent import get_comprehensive_agent

async def test_timeout_performance():
    """Test the agent's performance with timeout optimizations"""
    print("ğŸš€ Testing Comprehensive AI Agent Timeout Optimizations")
    print("=" * 60)
    
    agent = await get_comprehensive_agent()
    
    test_queries = [
        "What's the current inventory status?",
        "Show me ICU supplies",
        "I need to order masks urgently",
        "What alerts are active?",
        "Generate pharmacy analytics"
    ]
    
    total_start_time = time.time()
    
    for i, query in enumerate(test_queries, 1):
        print(f"\nğŸ” Test {i}: {query}")
        start_time = time.time()
        
        try:
            response = await agent.process_conversation(query, f"test_user_{i}")
            end_time = time.time()
            duration = end_time - start_time
            
            response_preview = response['response'][:150] + "..." if len(response['response']) > 150 else response['response']
            
            print(f"â±ï¸  Duration: {duration:.2f}s")
            print(f"ğŸ“Š Actions: {len(response.get('actions', []))}")
            print(f"ğŸ’¬ Response: {response_preview}")
            
            if duration < 12:
                print("âœ… Good response time!")
            elif duration < 20:
                print("âš ï¸  Acceptable response time")
            else:
                print("âŒ Slow response time")
                
        except Exception as e:
            print(f"âŒ Error: {e}")
    
    total_duration = time.time() - total_start_time
    print(f"\nğŸ“ˆ Total test duration: {total_duration:.2f}s")
    print(f"ğŸ“Š Average per query: {total_duration / len(test_queries):.2f}s")
    
    print("\nğŸ¯ Optimization Results:")
    print("â€¢ Timeout reduced from 30s â†’ 10s (first attempt)")
    print("â€¢ Retry timeout: 8s (with simplified prompt)")  
    print("â€¢ Intelligent fallback responses when LLM times out")
    print("â€¢ Prompt optimization for faster processing")
    print("â€¢ Gemini Flash model for speed over Gemini Pro")

if __name__ == "__main__":
    asyncio.run(test_timeout_performance())
